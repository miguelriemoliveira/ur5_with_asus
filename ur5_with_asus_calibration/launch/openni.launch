<?xml version="1.0"?>
<!--    Records raw depth image and RGB image from OpenNI device (kinect).
The depth image is registered with OpenNI firmware, using default calibration.-->
<launch>
  <!--  First we start the openni driver, and all the related
	post-processing to get point clouds: actually we don't need all that but in case you want to visualise it in action this is done. For an alternative that does not do that see http://mirror.umd.edu/roswiki/openni_launch(2f)Tutorials(2f)BagRecordingPlayback.html - just change the following line for the appropriate openni_camera node with depth registration switched on, and the rgb and depth frame ids set -->
  <!--	<include file="$(find openni_launch)/launch/openni.launch">
		<arg name="load_driver" value="true" />
		<arg name="depth_registration" value="true"/>
		<arg name="camera" value="kinect"/>
	</include>
-->
  <include file="$(find openni2_launch)/launch/openni2.launch">
    <arg name="load_driver" value="true"/>
    <arg name="depth_registration" value="true"/>
    <arg name="camera" value="camera"/>
    <arg name="publish_tf" value="false"/>
  </include>
  <param name="/camera/driver/data_skip" value="1"/>
  <node pkg="image_view" type="image_view" name="image_view_node" output="screen" args="image:=/camera/rgb/image_raw"/>
</launch>
